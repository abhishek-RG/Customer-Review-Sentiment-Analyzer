{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30cf2763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fedf946d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Head:\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "\n",
      "Sentiment Distribution:\n",
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the CSV file\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "# Display the first 5 rows to see what the data looks like\n",
    "print(\"Data Head:\")\n",
    "print(df.head())\n",
    "\n",
    "# Get a summary of the dataset\n",
    "print(\"\\nData Info:\")\n",
    "df.info()\n",
    "\n",
    "# Check the balance between positive and negative reviews\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "097ab8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (8000,)\n",
      "Testing data shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Using a sample of 10,000 reviews for quicker training\n",
    "df_sample = df.sample(n=10000, random_state=42)\n",
    "\n",
    "# Define our features (X) and target (y)\n",
    "X = df_sample['review']  # The text of the review\n",
    "y = df_sample['sentiment'] # The label (positive/negative)\n",
    "\n",
    "# Split the data into 80% for training and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af63f057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pipeline created:\n",
      "Pipeline(steps=[('tfidf', TfidfVectorizer(stop_words='english')),\n",
      "                ('classifier', LogisticRegression())])\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "print(\"Model pipeline created:\")\n",
    "print(model_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e480ef58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Model training complete! âœ…\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the model...\")\n",
    "# The pipeline handles both vectorizing the text and training the classifier\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training complete! âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8284afff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on the test set...\n",
      "\n",
      "Overall Accuracy: 0.8600 (86.00%)âœ…\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       992\n",
      "    positive       0.84      0.89      0.87      1008\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating the model on the test set...\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate and print the overall accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"\\nOverall Accuracy: {accuracy:.4f} ({accuracy:.2%})âœ…\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "# This shows precision, recall, and f1-score for each class (positive/negative)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18ef3223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: 'This movie was fantastic! I really enjoyed the acting and the plot was amazing.'\n",
      "Predicted Sentiment: positive ðŸ˜Š\n",
      "------------------------------\n",
      "Review: 'It was a complete waste of time. The script was boring and predictable.'\n",
      "Predicted Sentiment: negative ðŸ˜ \n"
     ]
    }
   ],
   "source": [
    "# Example 1: A positive review\n",
    "my_positive_review = \"This movie was fantastic! I really enjoyed the acting and the plot was amazing.\"\n",
    "prediction = model_pipeline.predict([my_positive_review])\n",
    "print(f\"Review: '{my_positive_review}'\")\n",
    "print(f\"Predicted Sentiment: {prediction[0]} ðŸ˜Š\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Example 2: A negative review\n",
    "my_negative_review = \"It was a complete waste of time. The script was boring and predictable.\"\n",
    "prediction = model_pipeline.predict([my_negative_review])\n",
    "print(f\"Review: '{my_negative_review}'\")\n",
    "print(f\"Predicted Sentiment: {prediction[0]} ðŸ˜ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b6cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584ebcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
